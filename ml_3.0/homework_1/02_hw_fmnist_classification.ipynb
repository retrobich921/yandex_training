{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Классификация FashionMNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm import tqdm\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "device\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 2048)\n",
    "        self.ac1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.ac2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(2048, 512)\n",
    "        self.ac3 = nn.ReLU()\n",
    "\n",
    "        self.fc4 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.ac1(self.fc1(x))\n",
    "        x = self.ac2(self.fc2(x))\n",
    "        x = self.ac3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = MyModel()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (fc1): Linear(in_features=784, out_features=2048, bias=True)\n",
       "  (ac1): ReLU()\n",
       "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (ac2): ReLU()\n",
       "  (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (ac3): ReLU()\n",
       "  (fc4): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:56<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def train(model, train_data_loader, criterion, optimizer, epochs):\n",
    "    # Включаем подсчет градиентов\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        for X, y in train_data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Предсказания нашей модели\n",
    "            y_pred = model(X.reshape(-1, 784))\n",
    "            # Посчитаем значение функции потерь на полученном предсказании\n",
    "            loss = criterion(y_pred, y)\n",
    "            # Подсчёт новых градиентов\n",
    "            loss.backward()\n",
    "            # Шаг градиентного спуска\n",
    "            optimizer.step()\n",
    "            # Обнуляем значения градиентов\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=1e-3)\n",
    "epochs = 30\n",
    "\n",
    "model, losses = train(model=model_task_1.to(device=device), train_data_loader=train_data_loader, criterion=criterion, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.94297\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.896\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Подсчет accuracy для каждого класса\n",
    "def compute_per_class_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct_per_class = torch.zeros(10).to(device)\n",
    "    total_per_class = torch.zeros(10).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                total_per_class[label] += 1\n",
    "                if predicted[i] == label:\n",
    "                    correct_per_class[label] += 1\n",
    "    \n",
    "    accuracy_per_class = correct_per_class / total_per_class * 100\n",
    "    \n",
    "    return accuracy_per_class, correct_per_class, total_per_class\n",
    "\n",
    "accuracy_per_class, correct_per_class, total_per_class = compute_per_class_accuracy(model_task_1, test_data_loader)\n",
    "\n",
    "print(\"Accuracy для каждого класса FashionMNIST:\")\n",
    "for i, acc in enumerate(accuracy_per_class):\n",
    "    print(f\"Класс {i} ({class_names[i]}): {acc:.2f}%\")\n",
    "\n",
    "correct = correct_per_class.sum().item()\n",
    "total = total_per_class.sum().item()\n",
    "overall_accuracy = 100 * correct / total\n",
    "print(f\"\\nОбщая accuracy: {overall_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/girafe-ai/ml-course/blob/25s_ml_trainings_3/homeworks/hw01_classification/hw_fmnist_data_dict.npy -O hw_fmnist_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Failed to interpret file 'hw_fmnist_data_dict.npy' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x0a'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f40fef935285>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloaded_data_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hw_fmnist_data_dict.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m submission_dict = {\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    468\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file 'hw_fmnist_data_dict.npy' as a pickle"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
